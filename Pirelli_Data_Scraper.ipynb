{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3450896c",
   "metadata": {},
   "source": [
    "# Pirelli F1 Tire Data Web Scraper\n",
    "\n",
    "This notebook scrapes official tire and circuit data from Pirelli's website to complement F1 tire degradation analysis.\n",
    "\n",
    "## Target Data:\n",
    "- **Tire Compounds**: Soft/Medium/Hard compound specifications (C1-C5)\n",
    "- **Circuit Length**: Track distance in km\n",
    "- **Track Characteristics** (1-5 scale):\n",
    "  - Traction\n",
    "  - Asphalt Grip\n",
    "  - Tire Stress\n",
    "  - Braking\n",
    "  - Lateral Forces\n",
    "  - Downforce\n",
    "  - Asphalt Abrasion\n",
    "  - Track Evolution\n",
    "\n",
    "## Output:\n",
    "Structured DataFrame/CSV with all circuit data for analysis integration."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac94cc57",
   "metadata": {},
   "source": [
    "## Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d26e92cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ•·ï¸ Pirelli Data Scraper Ready!\n",
      "ğŸ“Š Target: Tire compounds and circuit characteristics (2022-2024)\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import re\n",
    "import time\n",
    "from urllib.parse import urljoin, urlparse\n",
    "import json\n",
    "from typing import Dict, List, Optional\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"ğŸ•·ï¸ Pirelli Data Scraper Ready!\")\n",
    "print(\"ğŸ“Š Target: Tire compounds and circuit characteristics (2022-2024)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06ffefe5",
   "metadata": {},
   "source": [
    "## Scraper Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5d2fcef8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ¯ Target years: [2022, 2023, 2024]\n",
      "â±ï¸ Delay between requests: 1s\n"
     ]
    }
   ],
   "source": [
    "# Configuration\n",
    "BASE_URL = \"https://www.pirelli.com/global/en-ww/emotions-and-numbers/\"\n",
    "YEARS = [2022, 2023, 2024]\n",
    "DELAY_BETWEEN_REQUESTS = 1  # Seconds - be respectful to the server\n",
    "\n",
    "# Headers to mimic a real browser\n",
    "HEADERS = {\n",
    "    'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36',\n",
    "    'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8',\n",
    "    'Accept-Language': 'en-US,en;q=0.5',\n",
    "    'Accept-Encoding': 'gzip, deflate',\n",
    "    'Connection': 'keep-alive',\n",
    "    'Upgrade-Insecure-Requests': '1',\n",
    "}\n",
    "\n",
    "print(f\"ğŸ¯ Target years: {YEARS}\")\n",
    "print(f\"â±ï¸ Delay between requests: {DELAY_BETWEEN_REQUESTS}s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdaf8a36",
   "metadata": {},
   "source": [
    "## Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d2c94aab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Enhanced extraction functions loaded!\n"
     ]
    }
   ],
   "source": [
    "def get_page_content(url: str) -> Optional[BeautifulSoup]:\n",
    "    \"\"\"\n",
    "    Safely fetch and parse a web page.\n",
    "    \n",
    "    Args:\n",
    "        url: URL to fetch\n",
    "        \n",
    "    Returns:\n",
    "        BeautifulSoup object or None if failed\n",
    "    \"\"\"\n",
    "    try:\n",
    "        print(f\"ğŸ“¡ Fetching: {url}\")\n",
    "        response = requests.get(url, headers=HEADERS, timeout=10)\n",
    "        response.raise_for_status()\n",
    "        \n",
    "        soup = BeautifulSoup(response.content, 'html.parser')\n",
    "        time.sleep(DELAY_BETWEEN_REQUESTS)  # Be respectful\n",
    "        return soup\n",
    "        \n",
    "    except requests.RequestException as e:\n",
    "        print(f\"âŒ Error fetching {url}: {e}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "def extract_tire_compounds(soup: BeautifulSoup) -> Dict[str, str]:\n",
    "    \"\"\"\n",
    "    Extract tire compound information from Pirelli race pages.\n",
    "    \n",
    "    Args:\n",
    "        soup: Parsed HTML content\n",
    "        \n",
    "    Returns:\n",
    "        Dictionary with tire compound info\n",
    "    \"\"\"\n",
    "    compounds = {'soft': None, 'medium': None, 'hard': None}\n",
    "    \n",
    "    try:\n",
    "        page_text = soup.get_text()\n",
    "        \n",
    "        # Enhanced patterns for tire compounds\n",
    "        compound_patterns = [\n",
    "            # Pattern: \"Soft: C3\" or \"C3 (Soft)\"\n",
    "            (r'soft[:\\s\\-]*C([1-5])', 'soft'),\n",
    "            (r'medium[:\\s\\-]*C([1-5])', 'medium'), \n",
    "            (r'hard[:\\s\\-]*C([1-5])', 'hard'),\n",
    "            # Pattern: \"C3 (Soft)\" or \"C3 - Soft\"\n",
    "            (r'C([1-5])[:\\s\\-\\(]*soft', 'soft'),\n",
    "            (r'C([1-5])[:\\s\\-\\(]*medium', 'medium'),\n",
    "            (r'C([1-5])[:\\s\\-\\(]*hard', 'hard'),\n",
    "        ]\n",
    "        \n",
    "        for pattern, compound_type in compound_patterns:\n",
    "            matches = re.findall(pattern, page_text, re.IGNORECASE)\n",
    "            if matches and not compounds[compound_type]:  # Only set if not already found\n",
    "                compounds[compound_type] = f\"C{matches[0]}\"\n",
    "        \n",
    "        # Alternative: Look for compounds in image alt text or data attributes\n",
    "        images = soup.find_all('img')\n",
    "        for img in images:\n",
    "            alt_text = img.get('alt', '').lower()\n",
    "            src = img.get('src', '').lower()\n",
    "            \n",
    "            # Check for compound info in image metadata\n",
    "            for text in [alt_text, src]:\n",
    "                for pattern, compound_type in compound_patterns:\n",
    "                    matches = re.findall(pattern, text, re.IGNORECASE)\n",
    "                    if matches and not compounds[compound_type]:\n",
    "                        compounds[compound_type] = f\"C{matches[0]}\"\n",
    "        \n",
    "        # Remove None values and ensure we have valid compounds\n",
    "        compounds = {k: v for k, v in compounds.items() if v and re.match(r'C[1-5]', v)}\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âš ï¸ Error extracting tire compounds: {e}\")\n",
    "    \n",
    "    return compounds\n",
    "\n",
    "\n",
    "def extract_circuit_length(soup: BeautifulSoup) -> Optional[float]:\n",
    "    \"\"\"\n",
    "    Extract circuit length from Pirelli race pages.\n",
    "    \n",
    "    Args:\n",
    "        soup: Parsed HTML content\n",
    "        \n",
    "    Returns:\n",
    "        Circuit length in km or None\n",
    "    \"\"\"\n",
    "    try:\n",
    "        page_text = soup.get_text()\n",
    "        \n",
    "        # Enhanced patterns for circuit length\n",
    "        length_patterns = [\n",
    "            r'(\\d+\\.?\\d*)\\s*km',  # \"4.381 km\"\n",
    "            r'(\\d+,\\d+)\\s*km',    # \"4,381 km\" (European format)\n",
    "            r'length[:\\s]*(\\d+\\.?\\d*)',  # \"Length: 4.381\"\n",
    "            r'distance[:\\s]*(\\d+\\.?\\d*)', # \"Distance: 4.381\"\n",
    "            r'circuit[:\\s]*(\\d+\\.?\\d*)',  # \"Circuit: 4.381\"\n",
    "            r'track[:\\s]*(\\d+\\.?\\d*)'     # \"Track: 4.381\"\n",
    "        ]\n",
    "        \n",
    "        for pattern in length_patterns:\n",
    "            matches = re.findall(pattern, page_text, re.IGNORECASE)\n",
    "            if matches:\n",
    "                try:\n",
    "                    # Convert comma to dot for European number format\n",
    "                    length_str = matches[0].replace(',', '.')\n",
    "                    length = float(length_str)\n",
    "                    # Reasonable validation (F1 tracks are typically 3-7 km)\n",
    "                    if 2.0 <= length <= 8.0:\n",
    "                        return length\n",
    "                except ValueError:\n",
    "                    continue\n",
    "        \n",
    "        # Look in meta tags or structured data\n",
    "        meta_tags = soup.find_all('meta')\n",
    "        for meta in meta_tags:\n",
    "            content = meta.get('content', '')\n",
    "            if 'km' in content:\n",
    "                matches = re.findall(r'(\\d+\\.?\\d*)\\s*km', content)\n",
    "                if matches:\n",
    "                    try:\n",
    "                        length = float(matches[0])\n",
    "                        if 2.0 <= length <= 8.0:\n",
    "                            return length\n",
    "                    except ValueError:\n",
    "                        continue\n",
    "                \n",
    "    except Exception as e:\n",
    "        print(f\"âš ï¸ Error extracting circuit length: {e}\")\n",
    "    \n",
    "    return None\n",
    "\n",
    "\n",
    "def extract_track_characteristics(soup: BeautifulSoup) -> Dict[str, Optional[int]]:\n",
    "    \"\"\"\n",
    "    Extract track characteristics (1-5 scale ratings) from Pirelli pages.\n",
    "    \n",
    "    Args:\n",
    "        soup: Parsed HTML content\n",
    "        \n",
    "    Returns:\n",
    "        Dictionary with track characteristic ratings\n",
    "    \"\"\"\n",
    "    characteristics = {\n",
    "        'traction': None,\n",
    "        'asphalt_grip': None,\n",
    "        'tire_stress': None,\n",
    "        'braking': None,\n",
    "        'lateral': None,\n",
    "        'downforce': None,\n",
    "        'asphalt_abrasion': None,\n",
    "        'track_evolution': None\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        page_text = soup.get_text().lower()\n",
    "        \n",
    "        # Enhanced patterns for track characteristics\n",
    "        # These patterns look for the characteristic name followed by a rating\n",
    "        patterns = {\n",
    "            'traction': [r'traction[:\\s\\-]*([1-5])', r'([1-5])[:\\s\\-]*traction'],\n",
    "            'asphalt_grip': [r'(?:asphalt\\s*grip|grip)[:\\s\\-]*([1-5])', r'([1-5])[:\\s\\-]*(?:asphalt\\s*grip|grip)'],\n",
    "            'tire_stress': [r'(?:tire\\s*stress|tyre\\s*stress|stress)[:\\s\\-]*([1-5])', r'([1-5])[:\\s\\-]*(?:tire\\s*stress|tyre\\s*stress|stress)'],\n",
    "            'braking': [r'braking[:\\s\\-]*([1-5])', r'([1-5])[:\\s\\-]*braking'],\n",
    "            'lateral': [r'lateral[:\\s\\-]*([1-5])', r'([1-5])[:\\s\\-]*lateral'],\n",
    "            'downforce': [r'downforce[:\\s\\-]*([1-5])', r'([1-5])[:\\s\\-]*downforce'],\n",
    "            'asphalt_abrasion': [r'(?:asphalt\\s*abrasion|abrasion)[:\\s\\-]*([1-5])', r'([1-5])[:\\s\\-]*(?:asphalt\\s*abrasion|abrasion)'],\n",
    "            'track_evolution': [r'(?:track\\s*evolution|evolution)[:\\s\\-]*([1-5])', r'([1-5])[:\\s\\-]*(?:track\\s*evolution|evolution)']\n",
    "        }\n",
    "        \n",
    "        for char_name, pattern_list in patterns.items():\n",
    "            for pattern in pattern_list:\n",
    "                matches = re.findall(pattern, page_text)\n",
    "                if matches:\n",
    "                    try:\n",
    "                        rating = int(matches[0])\n",
    "                        if 1 <= rating <= 5:  # Validate rating is in expected range\n",
    "                            characteristics[char_name] = rating\n",
    "                            break  # Found valid rating, move to next characteristic\n",
    "                    except ValueError:\n",
    "                        continue\n",
    "        \n",
    "        # Look for characteristics in structured formats (tables, lists)\n",
    "        tables = soup.find_all('table')\n",
    "        for table in tables:\n",
    "            rows = table.find_all('tr')\n",
    "            for row in rows:\n",
    "                row_text = row.get_text().lower()\n",
    "                for char_name, pattern_list in patterns.items():\n",
    "                    if characteristics[char_name] is None:  # Only if not found yet\n",
    "                        for pattern in pattern_list:\n",
    "                            matches = re.findall(pattern, row_text)\n",
    "                            if matches:\n",
    "                                try:\n",
    "                                    rating = int(matches[0])\n",
    "                                    if 1 <= rating <= 5:\n",
    "                                        characteristics[char_name] = rating\n",
    "                                        break\n",
    "                                except ValueError:\n",
    "                                    continue\n",
    "        \n",
    "        # Look in definition lists\n",
    "        dl_elements = soup.find_all('dl')\n",
    "        for dl in dl_elements:\n",
    "            dl_text = dl.get_text().lower()\n",
    "            for char_name, pattern_list in patterns.items():\n",
    "                if characteristics[char_name] is None:\n",
    "                    for pattern in pattern_list:\n",
    "                        matches = re.findall(pattern, dl_text)\n",
    "                        if matches:\n",
    "                            try:\n",
    "                                rating = int(matches[0])\n",
    "                                if 1 <= rating <= 5:\n",
    "                                    characteristics[char_name] = rating\n",
    "                                    break\n",
    "                            except ValueError:\n",
    "                                continue\n",
    "                \n",
    "    except Exception as e:\n",
    "        print(f\"âš ï¸ Error extracting track characteristics: {e}\")\n",
    "    \n",
    "    return characteristics\n",
    "\n",
    "\n",
    "def get_race_links_for_year(year: int) -> List[str]:\n",
    "    \"\"\"\n",
    "    Extract F1 race infographic links using the discovered pattern.\n",
    "    \n",
    "    Pattern: https://www.pirelli.com/global/en-ww/emotions-and-numbers/[race-name]-YEAR-[id]/\n",
    "    \n",
    "    Args:\n",
    "        year: Year to scrape (2022-2024)\n",
    "        \n",
    "    Returns:\n",
    "        List of race page URLs\n",
    "    \"\"\"\n",
    "    year_url = f\"https://www.pirelli.com/global/en-ww/emotions-and-numbers/infographics-{year}/\"\n",
    "    soup = get_page_content(year_url)\n",
    "    \n",
    "    if not soup:\n",
    "        return []\n",
    "    \n",
    "    race_links = []\n",
    "    \n",
    "    try:\n",
    "        print(f\"ğŸ” Extracting F1 race links for {year}...\")\n",
    "        \n",
    "        # Find all links that:\n",
    "        # 1. Contain the year in the href\n",
    "        # 2. Have an associated image (indicating infographic)\n",
    "        # 3. Match the emotions-and-numbers pattern\n",
    "        # 4. Contain F1-related terms\n",
    "        \n",
    "        all_links = soup.find_all('a', href=True)\n",
    "        \n",
    "        for link in all_links:\n",
    "            href = link.get('href', '')\n",
    "            \n",
    "            # Check if this matches our pattern\n",
    "            if (str(year) in href and \n",
    "                link.find('img') and \n",
    "                'emotions-and-numbers' in href and\n",
    "                any(term in href.lower() for term in ['grand-prix', 'gp', 'formula-1', 'bahrain', 'australia', \n",
    "                                                     'japan', 'china', 'miami', 'spain', 'monaco', 'canada',\n",
    "                                                     'austria', 'britain', 'hungary', 'belgium', 'netherlands',\n",
    "                                                     'italy', 'singapore', 'qatar', 'usa', 'mexico', 'brazil',\n",
    "                                                     'vegas', 'abu-dhabi', 'saudi', 'azerbaijan', 'imola'])):\n",
    "                \n",
    "                # Ensure it's a full URL\n",
    "                if href.startswith('http'):\n",
    "                    full_url = href\n",
    "                else:\n",
    "                    full_url = urljoin(year_url, href)\n",
    "                \n",
    "                if full_url not in race_links:\n",
    "                    race_links.append(full_url)\n",
    "                    # Extract race name from URL for display\n",
    "                    race_name = href.split('/')[-2] if href.endswith('/') else href.split('/')[-1]\n",
    "                    race_name = race_name.replace('-', ' ').title()\n",
    "                    print(f\"  ğŸ {len(race_links):2d}. {race_name}\")\n",
    "        \n",
    "        print(f\"\\nâœ… Successfully extracted {len(race_links)} race links for {year}\")\n",
    "        \n",
    "        # Validate we have a reasonable number (F1 typically has 20-24 races)\n",
    "        if len(race_links) < 15:\n",
    "            print(f\"âš ï¸  Warning: Only found {len(race_links)} races. Expected 20-24 for a full F1 season.\")\n",
    "        elif len(race_links) > 25:\n",
    "            print(f\"âš ï¸  Warning: Found {len(race_links)} races. This seems high for F1.\")\n",
    "        else:\n",
    "            print(f\"âœ… Race count looks good for F1 season!\")\n",
    "        \n",
    "        return race_links\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Error extracting race links for {year}: {e}\")\n",
    "        return []\n",
    "\n",
    "\n",
    "print(\"âœ… Enhanced extraction functions loaded!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "686ee311",
   "metadata": {},
   "source": [
    "## Main Scraping Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "af5e84fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Main scraping functions loaded!\n"
     ]
    }
   ],
   "source": [
    "def scrape_race_data(race_url: str, year: int) -> Optional[Dict]:\n",
    "    \"\"\"\n",
    "    Scrape all tire and circuit data from a single race page.\n",
    "    \n",
    "    Args:\n",
    "        race_url: URL of the race page\n",
    "        year: Year of the race\n",
    "        \n",
    "    Returns:\n",
    "        Dictionary with all extracted data or None if failed\n",
    "    \"\"\"\n",
    "    soup = get_page_content(race_url)\n",
    "    if not soup:\n",
    "        return None\n",
    "    \n",
    "    try:\n",
    "        # Extract race name from URL or page title\n",
    "        race_name = \"Unknown\"\n",
    "        title_element = soup.find('title')\n",
    "        if title_element:\n",
    "            title_text = title_element.get_text()\n",
    "            # Clean up the title to get race name\n",
    "            race_name = title_text.split('|')[0].strip() if '|' in title_text else title_text.strip()\n",
    "        \n",
    "        # Extract all data\n",
    "        compounds = extract_tire_compounds(soup)\n",
    "        circuit_length = extract_circuit_length(soup)\n",
    "        characteristics = extract_track_characteristics(soup)\n",
    "        \n",
    "        # Combine all data\n",
    "        race_data = {\n",
    "            'year': year,\n",
    "            'race_name': race_name,\n",
    "            'url': race_url,\n",
    "            'circuit_length_km': circuit_length,\n",
    "            'soft_compound': compounds['soft'],\n",
    "            'medium_compound': compounds['medium'],\n",
    "            'hard_compound': compounds['hard'],\n",
    "            **characteristics  # Unpack all track characteristics\n",
    "        }\n",
    "        \n",
    "        print(f\"âœ… Extracted data for: {race_name} ({year})\")\n",
    "        return race_data\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Error scraping race data from {race_url}: {e}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "def scrape_all_pirelli_data(years: List[int] = YEARS) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Scrape tire and circuit data for all races across specified years.\n",
    "    \n",
    "    Args:\n",
    "        years: List of years to scrape\n",
    "        \n",
    "    Returns:\n",
    "        DataFrame with all race data\n",
    "    \"\"\"\n",
    "    all_race_data = []\n",
    "    \n",
    "    print(f\"ğŸš€ Starting Pirelli data scraping for years: {years}\")\n",
    "    print(f\"ğŸ“Š Target data: Tire compounds + 8 track characteristics\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    for year in years:\n",
    "        print(f\"\\nğŸ“… Processing year: {year}\")\n",
    "        \n",
    "        # Get all race links for this year\n",
    "        race_links = get_race_links_for_year(year)\n",
    "        \n",
    "        if not race_links:\n",
    "            print(f\"âš ï¸ No race links found for {year}\")\n",
    "            continue\n",
    "        \n",
    "        # Scrape each race\n",
    "        for i, race_url in enumerate(race_links, 1):\n",
    "            print(f\"\\nğŸ Race {i}/{len(race_links)} for {year}\")\n",
    "            \n",
    "            race_data = scrape_race_data(race_url, year)\n",
    "            if race_data:\n",
    "                all_race_data.append(race_data)\n",
    "            \n",
    "            # Extra delay between races\n",
    "            time.sleep(DELAY_BETWEEN_REQUESTS)\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(f\"ğŸ‰ Scraping complete! Collected data for {len(all_race_data)} races\")\n",
    "    \n",
    "    # Convert to DataFrame\n",
    "    df = pd.DataFrame(all_race_data)\n",
    "    \n",
    "    if not df.empty:\n",
    "        print(f\"ğŸ“Š DataFrame shape: {df.shape}\")\n",
    "        print(f\"ğŸ“‹ Columns: {list(df.columns)}\")\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "print(\"âœ… Main scraping functions loaded!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75801fd0",
   "metadata": {},
   "source": [
    "## Test Single Page First"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "54344201",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ§ª Testing scraper on Hungarian GP 2024 page...\n",
      "ğŸ“¡ Fetching: https://www.pirelli.com/global/en-ww/emotions-and-numbers/formula-1-hungarian-grand-prix-2024-136985/\n",
      "âœ… Successfully loaded Hungarian GP page\n",
      "ğŸ“„ Page title: FORMULA 1  HUNGARIAN  GRAND PRIX 2024 | Pirelli\n",
      "\n",
      "ğŸ–¼ï¸ Infographic images found:\n",
      "\n",
      "ğŸ› Tire compound references:\n",
      "Found compounds: set()\n",
      "\n",
      "ğŸ“ Circuit length references:\n",
      "Found lengths: []\n",
      "\n",
      "ğŸ“Š Potential ratings (1-5 scale):\n",
      "\n",
      "ğŸ“‹ Structured data:\n",
      "Found 1 JSON-LD scripts\n",
      "\n",
      "ğŸ“ Sample text content (first 1000 chars):\n",
      "FORMULA 1 HUNGARIAN GRAND PRIX 2024 | Pirelli IT EN ES BR DE FR ä¸­å›½ Stories Stories Road Racing Spot Life Road overview Car Motorcycles Bicycles Racing Spot overview Formula 1 Rally Gran Turismo Superbike Sailing Cycling Other Competitions E-sport Life overview Sustainability People Pirelli Calendar Lifestyle Innovation back Products Products Car Tyres Moto Tyres Bike Tyres Car Tyres overview Moto Tyres overview Bike Tyres overview back Lifestyle Lifestyle Pirelli Podium Cap Special Edition Pirelli Podium Cap Special Edition overview back About About Contact us Archive Pirelli in Brief What we do Pirelli's history Management Pirelli Headquarters Corporate Culture CERT Pirelli Total Efficiency 4.0 SUPPLIER'S AREA Consumer tyres OEM partnerships Racing Research & Development Indietro Indietro Indietro Sustainability Sustainability Archive Pirelli's Model ORGANIZATIONAL STRUCTURE Sustainability Policies Materiality Sustainability Plan & Targets Main performance indicators REPORTING CDP cli\n",
      "âœ… Successfully loaded Hungarian GP page\n",
      "ğŸ“„ Page title: FORMULA 1  HUNGARIAN  GRAND PRIX 2024 | Pirelli\n",
      "\n",
      "ğŸ–¼ï¸ Infographic images found:\n",
      "\n",
      "ğŸ› Tire compound references:\n",
      "Found compounds: set()\n",
      "\n",
      "ğŸ“ Circuit length references:\n",
      "Found lengths: []\n",
      "\n",
      "ğŸ“Š Potential ratings (1-5 scale):\n",
      "\n",
      "ğŸ“‹ Structured data:\n",
      "Found 1 JSON-LD scripts\n",
      "\n",
      "ğŸ“ Sample text content (first 1000 chars):\n",
      "FORMULA 1 HUNGARIAN GRAND PRIX 2024 | Pirelli IT EN ES BR DE FR ä¸­å›½ Stories Stories Road Racing Spot Life Road overview Car Motorcycles Bicycles Racing Spot overview Formula 1 Rally Gran Turismo Superbike Sailing Cycling Other Competitions E-sport Life overview Sustainability People Pirelli Calendar Lifestyle Innovation back Products Products Car Tyres Moto Tyres Bike Tyres Car Tyres overview Moto Tyres overview Bike Tyres overview back Lifestyle Lifestyle Pirelli Podium Cap Special Edition Pirelli Podium Cap Special Edition overview back About About Contact us Archive Pirelli in Brief What we do Pirelli's history Management Pirelli Headquarters Corporate Culture CERT Pirelli Total Efficiency 4.0 SUPPLIER'S AREA Consumer tyres OEM partnerships Racing Research & Development Indietro Indietro Indietro Sustainability Sustainability Archive Pirelli's Model ORGANIZATIONAL STRUCTURE Sustainability Policies Materiality Sustainability Plan & Targets Main performance indicators REPORTING CDP cli\n"
     ]
    }
   ],
   "source": [
    "# Test the scraper on the Hungarian GP page to understand the structure\n",
    "print(\"ğŸ§ª Testing scraper on Hungarian GP 2024 page...\")\n",
    "\n",
    "test_url = \"https://www.pirelli.com/global/en-ww/emotions-and-numbers/formula-1-hungarian-grand-prix-2024-136985/\"\n",
    "test_soup = get_page_content(test_url)\n",
    "\n",
    "if test_soup:\n",
    "    print(\"âœ… Successfully loaded Hungarian GP page\")\n",
    "    print(f\"ğŸ“„ Page title: {test_soup.find('title').get_text() if test_soup.find('title') else 'No title found'}\")\n",
    "    \n",
    "    # Look for infographic images and their alt text\n",
    "    print(\"\\nğŸ–¼ï¸ Infographic images found:\")\n",
    "    images = test_soup.find_all('img')\n",
    "    for i, img in enumerate(images):\n",
    "        src = img.get('src', '')\n",
    "        alt = img.get('alt', '')\n",
    "        if 'infographic' in src.lower() or 'info' in alt.lower() or any(keyword in alt.lower() for keyword in ['tire', 'compound', 'circuit', 'track']):\n",
    "            print(f\"  Image {i+1}: {alt} -> {src}\")\n",
    "    \n",
    "    # Look for tire compound mentions (C1-C5)\n",
    "    print(\"\\nğŸ› Tire compound references:\")\n",
    "    page_text = test_soup.get_text()\n",
    "    compound_matches = re.findall(r'C[1-5]', page_text)\n",
    "    print(f\"Found compounds: {set(compound_matches)}\")\n",
    "    \n",
    "    # Look for circuit length\n",
    "    print(\"\\nğŸ“ Circuit length references:\")\n",
    "    length_matches = re.findall(r'(\\d+\\.?\\d*)\\s*km', page_text, re.IGNORECASE)\n",
    "    print(f\"Found lengths: {length_matches}\")\n",
    "    \n",
    "    # Look for characteristic ratings (numbers 1-5)\n",
    "    print(\"\\nğŸ“Š Potential ratings (1-5 scale):\")\n",
    "    # Look for patterns like \"Traction: 3\" or similar\n",
    "    rating_patterns = [\n",
    "        r'traction[:\\s]*([1-5])',\n",
    "        r'grip[:\\s]*([1-5])',\n",
    "        r'stress[:\\s]*([1-5])',\n",
    "        r'braking[:\\s]*([1-5])',\n",
    "        r'lateral[:\\s]*([1-5])',\n",
    "        r'downforce[:\\s]*([1-5])',\n",
    "        r'abrasion[:\\s]*([1-5])',\n",
    "        r'evolution[:\\s]*([1-5])'\n",
    "    ]\n",
    "    \n",
    "    for pattern in rating_patterns:\n",
    "        matches = re.findall(pattern, page_text.lower())\n",
    "        if matches:\n",
    "            print(f\"  {pattern.split('[')[0]}: {matches}\")\n",
    "    \n",
    "    # Look for structured data (JSON-LD, data attributes, etc.)\n",
    "    print(\"\\nğŸ“‹ Structured data:\")\n",
    "    json_scripts = test_soup.find_all('script', type='application/ld+json')\n",
    "    print(f\"Found {len(json_scripts)} JSON-LD scripts\")\n",
    "    \n",
    "    # Look for data attributes\n",
    "    elements_with_data = test_soup.find_all(attrs={\"data-compound\": True})\n",
    "    if elements_with_data:\n",
    "        print(f\"Found {len(elements_with_data)} elements with data-compound attributes\")\n",
    "    \n",
    "    # Show some sample text content\n",
    "    print(\"\\nğŸ“ Sample text content (first 1000 chars):\")\n",
    "    clean_text = ' '.join(page_text.split())  # Clean up whitespace\n",
    "    print(clean_text[:1000])\n",
    "    \n",
    "else:\n",
    "    print(\"âŒ Failed to load Hungarian GP page\")\n",
    "    print(\"ğŸ’¡ Check URL and network connection\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93c35510",
   "metadata": {},
   "source": [
    "## Run Full Scraper\n",
    "\n",
    "**âš ï¸ Important Notes:**\n",
    "- This will make many requests to Pirelli's website\n",
    "- The scraper includes delays to be respectful\n",
    "- You may need to adjust the extraction functions based on the actual HTML structure\n",
    "- Run the test cell above first to verify the scraper works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38b5a26d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ¯ Starting with 2024 data only for testing...\n",
      "ğŸš€ Starting Pirelli data scraping for years: [2024]\n",
      "ğŸ“Š Target data: Tire compounds + 8 track characteristics\n",
      "==================================================\n",
      "\n",
      "ğŸ“… Processing year: 2024\n",
      "ğŸ“¡ Fetching: https://www.pirelli.com/global/en-ww/emotions-and-numbers/infographics-2024/\n",
      "ğŸ” Extracting F1 race links for 2024...\n",
      "  ğŸ  1. Formula 1 Gulf Air Bahrain Grand Prix 2024 120834\n",
      "  ğŸ  2. Formula 1 Rolex Australian Grand Prix 2024 123044\n",
      "  ğŸ  3. Gp Japan2024 124711\n",
      "  ğŸ  4. Gp China2024 127209\n",
      "  ğŸ  5. Formula 1 Crypto Com Miami Grand Prix 2024 128694\n",
      "  ğŸ  6. Formula 1 Msc Cruises Gran Premio Del Made In Italy E Dell Emilia Romagna 2024 129842\n",
      "  ğŸ  7. Formula 1 Grand Prix De Monaco 2024 130812\n",
      "  ğŸ  8. Formula 1 Pirelli Grand Prix Du Canada 2024 131658\n",
      "  ğŸ  9. Formula 1 Aramco Gran Premio De Espana 2024 133752\n",
      "  ğŸ 10. Formula 1 Qatar Airways Austrian Grand Prix 2024 134873\n",
      "  ğŸ 11. Formula 1 Qatar Airways British Grand Prix 2024 135487\n",
      "  ğŸ 12. Formula 1 Hungarian Grand Prix 2024 136985\n",
      "  ğŸ 13. Formula 1 Rolex Belgian Grand Prix 2024 137042\n",
      "  ğŸ 14. Formula 1 Heineken Dutch Grand Prix 2024 139980\n",
      "  ğŸ 15. Formula 1 Pirelli Gran Premio D Italia 2024 140854\n",
      "  ğŸ 16. Formula 1 Qatar Airways Azerbaijan Grand Prix 2024 141517\n",
      "  ğŸ 17. Formula 1 Singapore Airlines Singapore Grand Prix 2024 142696\n",
      "  ğŸ 18. Formula 1 Pirelli United States Grand Prix 2024 144632\n",
      "  ğŸ 19. Formula 1 Gran Premio De La Ciudad De Mexico 2024 146014\n",
      "  ğŸ 20. Formula 1 Lenovo Grande Premio De Sao Paulo 2024 146847\n",
      "  ğŸ 21. Formula 1 Heineken Silver Las Vegas Grand Prix 2024 148505\n",
      "  ğŸ 22. Formula 1 Qatar Airways Qatar Grand Prix 2024 149275\n",
      "  ğŸ 23. Formula 1 Etihad Airways Abu Dhabi Grand Prix 2024 149872\n",
      "\n",
      "âœ… Successfully extracted 23 race links for 2024\n",
      "âœ… Race count looks good for F1 season!\n",
      "\n",
      "ğŸ Race 1/23 for 2024\n",
      "ğŸ“¡ Fetching: https://www.pirelli.com/global/en-ww/emotions-and-numbers/formula-1-gulf-air-bahrain-grand-prix-2024-120834/\n",
      "ğŸ” Extracting F1 race links for 2024...\n",
      "  ğŸ  1. Formula 1 Gulf Air Bahrain Grand Prix 2024 120834\n",
      "  ğŸ  2. Formula 1 Rolex Australian Grand Prix 2024 123044\n",
      "  ğŸ  3. Gp Japan2024 124711\n",
      "  ğŸ  4. Gp China2024 127209\n",
      "  ğŸ  5. Formula 1 Crypto Com Miami Grand Prix 2024 128694\n",
      "  ğŸ  6. Formula 1 Msc Cruises Gran Premio Del Made In Italy E Dell Emilia Romagna 2024 129842\n",
      "  ğŸ  7. Formula 1 Grand Prix De Monaco 2024 130812\n",
      "  ğŸ  8. Formula 1 Pirelli Grand Prix Du Canada 2024 131658\n",
      "  ğŸ  9. Formula 1 Aramco Gran Premio De Espana 2024 133752\n",
      "  ğŸ 10. Formula 1 Qatar Airways Austrian Grand Prix 2024 134873\n",
      "  ğŸ 11. Formula 1 Qatar Airways British Grand Prix 2024 135487\n",
      "  ğŸ 12. Formula 1 Hungarian Grand Prix 2024 136985\n",
      "  ğŸ 13. Formula 1 Rolex Belgian Grand Prix 2024 137042\n",
      "  ğŸ 14. Formula 1 Heineken Dutch Grand Prix 2024 139980\n",
      "  ğŸ 15. Formula 1 Pirelli Gran Premio D Italia 2024 140854\n",
      "  ğŸ 16. Formula 1 Qatar Airways Azerbaijan Grand Prix 2024 141517\n",
      "  ğŸ 17. Formula 1 Singapore Airlines Singapore Grand Prix 2024 142696\n",
      "  ğŸ 18. Formula 1 Pirelli United States Grand Prix 2024 144632\n",
      "  ğŸ 19. Formula 1 Gran Premio De La Ciudad De Mexico 2024 146014\n",
      "  ğŸ 20. Formula 1 Lenovo Grande Premio De Sao Paulo 2024 146847\n",
      "  ğŸ 21. Formula 1 Heineken Silver Las Vegas Grand Prix 2024 148505\n",
      "  ğŸ 22. Formula 1 Qatar Airways Qatar Grand Prix 2024 149275\n",
      "  ğŸ 23. Formula 1 Etihad Airways Abu Dhabi Grand Prix 2024 149872\n",
      "\n",
      "âœ… Successfully extracted 23 race links for 2024\n",
      "âœ… Race count looks good for F1 season!\n",
      "\n",
      "ğŸ Race 1/23 for 2024\n",
      "ğŸ“¡ Fetching: https://www.pirelli.com/global/en-ww/emotions-and-numbers/formula-1-gulf-air-bahrain-grand-prix-2024-120834/\n",
      "âŒ Error scraping race data from https://www.pirelli.com/global/en-ww/emotions-and-numbers/formula-1-gulf-air-bahrain-grand-prix-2024-120834/: 'soft'\n",
      "âŒ Error scraping race data from https://www.pirelli.com/global/en-ww/emotions-and-numbers/formula-1-gulf-air-bahrain-grand-prix-2024-120834/: 'soft'\n",
      "\n",
      "ğŸ Race 2/23 for 2024\n",
      "ğŸ“¡ Fetching: https://www.pirelli.com/global/en-ww/emotions-and-numbers/formula-1-rolex-australian-grand-prix-2024-123044/\n",
      "\n",
      "ğŸ Race 2/23 for 2024\n",
      "ğŸ“¡ Fetching: https://www.pirelli.com/global/en-ww/emotions-and-numbers/formula-1-rolex-australian-grand-prix-2024-123044/\n",
      "âŒ Error scraping race data from https://www.pirelli.com/global/en-ww/emotions-and-numbers/formula-1-rolex-australian-grand-prix-2024-123044/: 'soft'\n",
      "âŒ Error scraping race data from https://www.pirelli.com/global/en-ww/emotions-and-numbers/formula-1-rolex-australian-grand-prix-2024-123044/: 'soft'\n",
      "\n",
      "ğŸ Race 3/23 for 2024\n",
      "ğŸ“¡ Fetching: https://www.pirelli.com/global/en-ww/emotions-and-numbers/gp-japan2024-124711/\n",
      "\n",
      "ğŸ Race 3/23 for 2024\n",
      "ğŸ“¡ Fetching: https://www.pirelli.com/global/en-ww/emotions-and-numbers/gp-japan2024-124711/\n",
      "âŒ Error scraping race data from https://www.pirelli.com/global/en-ww/emotions-and-numbers/gp-japan2024-124711/: 'soft'\n",
      "âŒ Error scraping race data from https://www.pirelli.com/global/en-ww/emotions-and-numbers/gp-japan2024-124711/: 'soft'\n",
      "\n",
      "ğŸ Race 4/23 for 2024\n",
      "ğŸ“¡ Fetching: https://www.pirelli.com/global/en-ww/emotions-and-numbers/gp-china2024-127209/\n",
      "\n",
      "ğŸ Race 4/23 for 2024\n",
      "ğŸ“¡ Fetching: https://www.pirelli.com/global/en-ww/emotions-and-numbers/gp-china2024-127209/\n",
      "âŒ Error scraping race data from https://www.pirelli.com/global/en-ww/emotions-and-numbers/gp-china2024-127209/: 'soft'\n",
      "âŒ Error scraping race data from https://www.pirelli.com/global/en-ww/emotions-and-numbers/gp-china2024-127209/: 'soft'\n",
      "\n",
      "ğŸ Race 5/23 for 2024\n",
      "ğŸ“¡ Fetching: https://www.pirelli.com/global/en-ww/emotions-and-numbers/formula-1-crypto-com-miami-grand-prix-2024-128694/\n",
      "\n",
      "ğŸ Race 5/23 for 2024\n",
      "ğŸ“¡ Fetching: https://www.pirelli.com/global/en-ww/emotions-and-numbers/formula-1-crypto-com-miami-grand-prix-2024-128694/\n",
      "âŒ Error scraping race data from https://www.pirelli.com/global/en-ww/emotions-and-numbers/formula-1-crypto-com-miami-grand-prix-2024-128694/: 'soft'\n",
      "âŒ Error scraping race data from https://www.pirelli.com/global/en-ww/emotions-and-numbers/formula-1-crypto-com-miami-grand-prix-2024-128694/: 'soft'\n",
      "\n",
      "ğŸ Race 6/23 for 2024\n",
      "ğŸ“¡ Fetching: https://www.pirelli.com/global/en-ww/emotions-and-numbers/formula-1-msc-cruises-gran-premio-del-made-in-italy-e-dell-emilia-romagna-2024-129842/\n",
      "\n",
      "ğŸ Race 6/23 for 2024\n",
      "ğŸ“¡ Fetching: https://www.pirelli.com/global/en-ww/emotions-and-numbers/formula-1-msc-cruises-gran-premio-del-made-in-italy-e-dell-emilia-romagna-2024-129842/\n",
      "âŒ Error scraping race data from https://www.pirelli.com/global/en-ww/emotions-and-numbers/formula-1-msc-cruises-gran-premio-del-made-in-italy-e-dell-emilia-romagna-2024-129842/: 'soft'\n",
      "âŒ Error scraping race data from https://www.pirelli.com/global/en-ww/emotions-and-numbers/formula-1-msc-cruises-gran-premio-del-made-in-italy-e-dell-emilia-romagna-2024-129842/: 'soft'\n",
      "\n",
      "ğŸ Race 7/23 for 2024\n",
      "ğŸ“¡ Fetching: https://www.pirelli.com/global/en-ww/emotions-and-numbers/formula-1-grand-prix-de-monaco-2024-130812/\n",
      "\n",
      "ğŸ Race 7/23 for 2024\n",
      "ğŸ“¡ Fetching: https://www.pirelli.com/global/en-ww/emotions-and-numbers/formula-1-grand-prix-de-monaco-2024-130812/\n",
      "âŒ Error scraping race data from https://www.pirelli.com/global/en-ww/emotions-and-numbers/formula-1-grand-prix-de-monaco-2024-130812/: 'soft'\n",
      "âŒ Error scraping race data from https://www.pirelli.com/global/en-ww/emotions-and-numbers/formula-1-grand-prix-de-monaco-2024-130812/: 'soft'\n",
      "\n",
      "ğŸ Race 8/23 for 2024\n",
      "ğŸ“¡ Fetching: https://www.pirelli.com/global/en-ww/emotions-and-numbers/formula-1-pirelli-grand-prix-du-canada-2024-131658/\n",
      "\n",
      "ğŸ Race 8/23 for 2024\n",
      "ğŸ“¡ Fetching: https://www.pirelli.com/global/en-ww/emotions-and-numbers/formula-1-pirelli-grand-prix-du-canada-2024-131658/\n",
      "âŒ Error scraping race data from https://www.pirelli.com/global/en-ww/emotions-and-numbers/formula-1-pirelli-grand-prix-du-canada-2024-131658/: 'soft'\n",
      "âŒ Error scraping race data from https://www.pirelli.com/global/en-ww/emotions-and-numbers/formula-1-pirelli-grand-prix-du-canada-2024-131658/: 'soft'\n",
      "\n",
      "ğŸ Race 9/23 for 2024\n",
      "ğŸ“¡ Fetching: https://www.pirelli.com/global/en-ww/emotions-and-numbers/formula-1-aramco-gran-premio-de-espana-2024-133752/\n",
      "\n",
      "ğŸ Race 9/23 for 2024\n",
      "ğŸ“¡ Fetching: https://www.pirelli.com/global/en-ww/emotions-and-numbers/formula-1-aramco-gran-premio-de-espana-2024-133752/\n"
     ]
    }
   ],
   "source": [
    "# Run the full scraper (uncomment when ready)\n",
    "# pirelli_data = scrape_all_pirelli_data()\n",
    "\n",
    "# For now, let's start with just one year to test\n",
    "print(\"ğŸ¯ Starting with 2024 data only for testing...\")\n",
    "pirelli_data = scrape_all_pirelli_data([2024])\n",
    "\n",
    "# Display results\n",
    "if not pirelli_data.empty:\n",
    "    print(\"\\nğŸ“Š Scraped Data Summary:\")\n",
    "    print(pirelli_data.head())\n",
    "    \n",
    "    print(\"\\nğŸ“ˆ Data Info:\")\n",
    "    print(pirelli_data.info())\n",
    "    \n",
    "    print(f\"\\nâœ… Successfully scraped {len(pirelli_data)} races\")\n",
    "    \n",
    "else:\n",
    "    print(\"âŒ No data scraped\")\n",
    "    print(\"ğŸ’¡ This is expected since the data extraction functions need refinement for the infographic format\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e171ffc",
   "metadata": {},
   "source": [
    "## âœ… Current Status\n",
    "\n",
    "**Race Link Extraction: WORKING** \n",
    "- Successfully extracting 23 race links for 2024 (correct number for F1 season)\n",
    "- Pattern identified: `<a href=\"...race...\"><img ...></a>` with year in URL\n",
    "- Function `get_race_links_for_year()` is working properly\n",
    "\n",
    "**Next Steps:**\n",
    "- The race links are working perfectly\n",
    "- Data extraction from individual race pages needs refinement (tire compounds, circuit characteristics)\n",
    "- The infographic data is likely embedded in images rather than text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9aa40786",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ” Debugging main page: https://www.pirelli.com/global/en-ww/emotions-and-numbers/infographics-2024/\n",
      "ğŸ“Š Response status: 200\n",
      "ğŸ”— Total links found: 256\n",
      "ğŸ Potential race links found: 35\n",
      "  1. Text: 'Racing Spot'\n",
      "     URL: https://www.pirelli.com/global/en-ww/race/racingspot/\n",
      "\n",
      "  2. Text: 'Racing Spot overview'\n",
      "     URL: https://www.pirelli.com/global/en-ww/race/racingspot/\n",
      "\n",
      "  3. Text: 'Formula 1'\n",
      "     URL: https://www.pirelli.com/global/en-ww/race/racingspot/formula-1/\n",
      "\n",
      "  4. Text: 'Rally'\n",
      "     URL: https://www.pirelli.com/global/en-ww/race/racingspot/rally/\n",
      "\n",
      "  5. Text: 'Gran Turismo'\n",
      "     URL: https://www.pirelli.com/global/en-ww/race/racingspot/gran-turismo/\n",
      "\n",
      "  6. Text: 'Superbike'\n",
      "     URL: https://www.pirelli.com/global/en-ww/race/racingspot/superbike/\n",
      "\n",
      "  7. Text: 'Sailing'\n",
      "     URL: https://www.pirelli.com/global/en-ww/race/racingspot/sailing/\n",
      "\n",
      "  8. Text: 'Cycling'\n",
      "     URL: https://www.pirelli.com/global/en-ww/race/racingspot/cycling/\n",
      "\n",
      "  9. Text: 'Other Competitions'\n",
      "     URL: https://www.pirelli.com/global/en-ww/race/racingspot/other-competitions/\n",
      "\n",
      "  10. Text: 'E-sport'\n",
      "     URL: https://www.pirelli.com/global/en-ww/race/racingspot/e-sports/\n",
      "\n",
      "ğŸ“ˆ Infographic links found: 0\n",
      "ğŸ“Š Response status: 200\n",
      "ğŸ”— Total links found: 256\n",
      "ğŸ Potential race links found: 35\n",
      "  1. Text: 'Racing Spot'\n",
      "     URL: https://www.pirelli.com/global/en-ww/race/racingspot/\n",
      "\n",
      "  2. Text: 'Racing Spot overview'\n",
      "     URL: https://www.pirelli.com/global/en-ww/race/racingspot/\n",
      "\n",
      "  3. Text: 'Formula 1'\n",
      "     URL: https://www.pirelli.com/global/en-ww/race/racingspot/formula-1/\n",
      "\n",
      "  4. Text: 'Rally'\n",
      "     URL: https://www.pirelli.com/global/en-ww/race/racingspot/rally/\n",
      "\n",
      "  5. Text: 'Gran Turismo'\n",
      "     URL: https://www.pirelli.com/global/en-ww/race/racingspot/gran-turismo/\n",
      "\n",
      "  6. Text: 'Superbike'\n",
      "     URL: https://www.pirelli.com/global/en-ww/race/racingspot/superbike/\n",
      "\n",
      "  7. Text: 'Sailing'\n",
      "     URL: https://www.pirelli.com/global/en-ww/race/racingspot/sailing/\n",
      "\n",
      "  8. Text: 'Cycling'\n",
      "     URL: https://www.pirelli.com/global/en-ww/race/racingspot/cycling/\n",
      "\n",
      "  9. Text: 'Other Competitions'\n",
      "     URL: https://www.pirelli.com/global/en-ww/race/racingspot/other-competitions/\n",
      "\n",
      "  10. Text: 'E-sport'\n",
      "     URL: https://www.pirelli.com/global/en-ww/race/racingspot/e-sports/\n",
      "\n",
      "ğŸ“ˆ Infographic links found: 0\n"
     ]
    }
   ],
   "source": [
    "# Debug: Fetch and analyze the main Pirelli page structure\n",
    "debug_url = \"https://www.pirelli.com/global/en-ww/emotions-and-numbers/infographics-2024/\"\n",
    "print(f\"ğŸ” Debugging main page: {debug_url}\")\n",
    "\n",
    "try:\n",
    "    debug_response = requests.get(debug_url, headers=HEADERS, timeout=30)\n",
    "    print(f\"ğŸ“Š Response status: {debug_response.status_code}\")\n",
    "    \n",
    "    if debug_response.status_code == 200:\n",
    "        debug_soup = BeautifulSoup(debug_response.content, 'html.parser')\n",
    "        \n",
    "        # Look for all links on the page\n",
    "        all_links = debug_soup.find_all('a', href=True)\n",
    "        print(f\"ğŸ”— Total links found: {len(all_links)}\")\n",
    "        \n",
    "        # Look for links that might contain race information\n",
    "        race_keywords = ['grand-prix', 'gp', 'race', 'circuit', 'track', 'bahrain', 'saudi', 'australia', 'japan', 'china', 'miami', 'imola', 'monaco', 'canada', 'spain', 'austria', 'britain', 'hungary', 'belgium', 'netherlands', 'italy', 'singapore', 'usa', 'mexico', 'brazil', 'vegas', 'qatar', 'abu-dhabi']\n",
    "        \n",
    "        potential_race_links = []\n",
    "        for link in all_links:\n",
    "            href = link.get('href', '').lower()\n",
    "            text = link.get_text(strip=True).lower()\n",
    "            \n",
    "            # Check if any race keywords are in the href or text\n",
    "            if any(keyword in href or keyword in text for keyword in race_keywords):\n",
    "                potential_race_links.append({\n",
    "                    'href': link.get('href'),\n",
    "                    'text': link.get_text(strip=True),\n",
    "                    'full_url': urljoin(debug_url, link.get('href'))\n",
    "                })\n",
    "        \n",
    "        print(f\"ğŸ Potential race links found: {len(potential_race_links)}\")\n",
    "        \n",
    "        # Show first few potential race links\n",
    "        for i, link in enumerate(potential_race_links[:10]):\n",
    "            print(f\"  {i+1}. Text: '{link['text']}'\")\n",
    "            print(f\"     URL: {link['full_url']}\")\n",
    "            print()\n",
    "            \n",
    "        # Also check for any links with infographics in the URL\n",
    "        infographic_links = [link for link in all_links if 'infographic' in link.get('href', '').lower()]\n",
    "        print(f\"ğŸ“ˆ Infographic links found: {len(infographic_links)}\")\n",
    "        \n",
    "        for i, link in enumerate(infographic_links[:5]):\n",
    "            print(f\"  {i+1}. Text: '{link.get_text(strip=True)}'\")\n",
    "            print(f\"     URL: {urljoin(debug_url, link.get('href'))}\")\n",
    "            \n",
    "    else:\n",
    "        print(f\"âŒ Failed to fetch page: {debug_response.status_code}\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"âŒ Error debugging page: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "932650cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ” Looking for specific content patterns...\n",
      "ğŸ Race names found in page text: []\n",
      "ğŸ“œ Script tags found: 11\n",
      "\n",
      "ğŸ“œ Script 2 content preview (first 200 chars):\n",
      "if (\n",
      "    (!window.cookieBarAdded || window.cookieBarAdded === undefined) &&\n",
      "    window.location.host !== \"kolumbus-pirelli-preprod.dshare.cloud\"\n",
      "  ) {\n",
      "    analyticsEvent = function () {};\n",
      "    analytic...\n",
      "\n",
      "ğŸ“œ Script 3 content preview (first 200 chars):\n",
      "/* <![CDATA[ */\n",
      "  var google_conversion_id = 882404798;\n",
      "  var google_custom_params = window.google_tag_params;\n",
      "  var google_remarketing_only = true;\n",
      "  /* ]]> */\n",
      "\n",
      "ğŸ“œ Script 5 content preview (first 200 chars):\n",
      "<div class=\"lightbox-wrapper\">\n",
      "    <div class=\"over-lightbox\"></div>\n",
      "    <div class=\"lightbox\">\n",
      "      <a title=\"Close\" class=\"close-lightbox\" href=\"javascript:void(0)\">&times;</a>\n",
      "      <div class=\"co...\n",
      "\n",
      "ğŸ¯ Relevant containers found: 0\n"
     ]
    }
   ],
   "source": [
    "# Deeper analysis of the page content\n",
    "print(\"ğŸ” Looking for specific content patterns...\")\n",
    "\n",
    "# Look for any mention of race names or F1 circuits\n",
    "page_text = debug_soup.get_text().lower()\n",
    "race_names = ['bahrain', 'saudi arabia', 'australia', 'japan', 'china', 'miami', 'imola', 'monaco', 'canada', 'spain', 'austria', 'britain', 'hungary', 'belgium', 'netherlands', 'italy', 'singapore', 'usa', 'mexico', 'brazil', 'las vegas', 'qatar', 'abu dhabi']\n",
    "\n",
    "found_races = []\n",
    "for race in race_names:\n",
    "    if race in page_text:\n",
    "        found_races.append(race)\n",
    "\n",
    "print(f\"ğŸ Race names found in page text: {found_races}\")\n",
    "\n",
    "# Look for script tags that might contain dynamic content\n",
    "scripts = debug_soup.find_all('script')\n",
    "print(f\"ğŸ“œ Script tags found: {len(scripts)}\")\n",
    "\n",
    "# Check for any JSON or data structures in scripts\n",
    "for i, script in enumerate(scripts[:5]):  # Check first 5 scripts\n",
    "    if script.string:\n",
    "        content = script.string.strip()\n",
    "        if len(content) > 0:\n",
    "            print(f\"\\nğŸ“œ Script {i+1} content preview (first 200 chars):\")\n",
    "            print(content[:200] + \"...\" if len(content) > 200 else content)\n",
    "\n",
    "# Look for div/section tags that might contain race data\n",
    "race_containers = debug_soup.find_all(['div', 'section'], class_=True)\n",
    "relevant_containers = []\n",
    "\n",
    "for container in race_containers:\n",
    "    class_names = ' '.join(container.get('class', []))\n",
    "    if any(keyword in class_names.lower() for keyword in ['race', 'grand', 'prix', 'circuit', 'infographic']):\n",
    "        relevant_containers.append({\n",
    "            'tag': container.name,\n",
    "            'classes': class_names,\n",
    "            'text_preview': container.get_text(strip=True)[:100]\n",
    "        })\n",
    "\n",
    "print(f\"\\nğŸ¯ Relevant containers found: {len(relevant_containers)}\")\n",
    "for i, container in enumerate(relevant_containers[:5]):\n",
    "    print(f\"  {i+1}. Tag: {container['tag']}, Classes: {container['classes']}\")\n",
    "    print(f\"     Preview: {container['text_preview']}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fa8434c",
   "metadata": {},
   "source": [
    "## Save Data to CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "185b7601",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âŒ No data to save\n"
     ]
    }
   ],
   "source": [
    "# Save the data to CSV for use in your tire degradation analysis\n",
    "if not pirelli_data.empty:\n",
    "    output_file = \"pirelli_tire_circuit_data.csv\"\n",
    "    pirelli_data.to_csv(output_file, index=False)\n",
    "    \n",
    "    print(f\"ğŸ’¾ Data saved to: {output_file}\")\n",
    "    print(f\"ğŸ“Š Shape: {pirelli_data.shape}\")\n",
    "    print(f\"ğŸ“‹ Columns: {list(pirelli_data.columns)}\")\n",
    "    \n",
    "    # Show data quality summary\n",
    "    print(\"\\nğŸ” Data Quality Summary:\")\n",
    "    missing_data = pirelli_data.isnull().sum()\n",
    "    print(missing_data[missing_data > 0])\n",
    "    \n",
    "    # Show unique tire compounds found\n",
    "    print(\"\\nğŸ› Tire Compounds Found:\")\n",
    "    for compound_type in ['soft_compound', 'medium_compound', 'hard_compound']:\n",
    "        if compound_type in pirelli_data.columns:\n",
    "            unique_compounds = pirelli_data[compound_type].dropna().unique()\n",
    "            print(f\"  {compound_type}: {unique_compounds}\")\n",
    "    \n",
    "else:\n",
    "    print(\"âŒ No data to save\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b64a2975",
   "metadata": {},
   "source": [
    "## Integration with F1 Analysis\n",
    "\n",
    "Once you have the Pirelli data, you can merge it with your FastF1 analysis:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "31eecb3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âŒ No data available for integration example\n"
     ]
    }
   ],
   "source": [
    "# Example of how to integrate with your F1 tire degradation analysis\n",
    "if not pirelli_data.empty:\n",
    "    print(\"ğŸ”— Integration Example:\")\n",
    "    print(\"\"\"# In your F1 analysis notebook:\n",
    "    \n",
    "import pandas as pd\n",
    "import fastf1\n",
    "\n",
    "# Load Pirelli data\n",
    "pirelli_data = pd.read_csv('pirelli_tire_circuit_data.csv')\n",
    "\n",
    "# Load F1 session\n",
    "session = fastf1.get_session(2024, \"Bahrain\", \"R\")\n",
    "session.load()\n",
    "\n",
    "# Process with your functions\n",
    "processed_laps = process_race_for_tire_analysis(session)\n",
    "\n",
    "# Merge with circuit characteristics\n",
    "race_name = \"Bahrain Grand Prix\"  # Match with pirelli_data\n",
    "circuit_data = pirelli_data[pirelli_data['race_name'].str.contains('Bahrain')]\n",
    "\n",
    "if not circuit_data.empty:\n",
    "    # Add circuit characteristics to your lap data\n",
    "    for col in ['traction', 'asphalt_grip', 'tire_stress', 'braking']:\n",
    "        if col in circuit_data.columns:\n",
    "            processed_laps[f'circuit_{col}'] = circuit_data[col].iloc[0]\n",
    "\n",
    "# Now you have lap-by-lap data with official circuit characteristics!\n",
    "# Perfect for advanced tire degradation modeling\n",
    "\"\"\")\n",
    "    \n",
    "    print(\"\\nğŸ¯ Benefits:\")\n",
    "    print(\"âœ… Official tire compound data (C1-C5)\")\n",
    "    print(\"âœ… Circuit characteristics for modeling\")\n",
    "    print(\"âœ… Track evolution and abrasion data\")\n",
    "    print(\"âœ… Braking and lateral force intensity\")\n",
    "    print(\"âœ… Perfect complement to your FastF1 analysis!\")\n",
    "\n",
    "else:\n",
    "    print(\"âŒ No data available for integration example\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce6341bc",
   "metadata": {},
   "source": [
    "## Troubleshooting and Refinement\n",
    "\n",
    "If the scraper doesn't work perfectly on the first try, here are debugging tools:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d97284b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ”§ Enhanced debug function ready!\n",
      "ğŸ“ Run: debug_pirelli_race_page('URL') to analyze a specific page\n",
      "ğŸ” Deep analysis of: https://www.pirelli.com/global/en-ww/emotions-and-numbers/formula-1-hungarian-grand-prix-2024-136985/\n",
      "ğŸ“¡ Fetching: https://www.pirelli.com/global/en-ww/emotions-and-numbers/formula-1-hungarian-grand-prix-2024-136985/\n",
      "\n",
      "ğŸ“„ Page title:\n",
      "FORMULA 1  HUNGARIAN  GRAND PRIX 2024 | Pirelli\n",
      "\n",
      "ğŸ¯ Main content structure:\n",
      "âœ… Found main content area\n",
      "\n",
      "ğŸ–¼ï¸ Infographic analysis:\n",
      "Found 2 potential infographic containers\n",
      "\n",
      "ğŸ› Tire compound extraction:\n",
      "Compound patterns found: {}\n",
      "\n",
      "ğŸ“Š Track characteristics analysis:\n",
      "\n",
      "ğŸ“ Circuit length detection:\n",
      "\n",
      "ğŸ“„ Page title:\n",
      "FORMULA 1  HUNGARIAN  GRAND PRIX 2024 | Pirelli\n",
      "\n",
      "ğŸ¯ Main content structure:\n",
      "âœ… Found main content area\n",
      "\n",
      "ğŸ–¼ï¸ Infographic analysis:\n",
      "Found 2 potential infographic containers\n",
      "\n",
      "ğŸ› Tire compound extraction:\n",
      "Compound patterns found: {}\n",
      "\n",
      "ğŸ“Š Track characteristics analysis:\n",
      "\n",
      "ğŸ“ Circuit length detection:\n"
     ]
    }
   ],
   "source": [
    "# Enhanced debug function for Pirelli pages\n",
    "def debug_pirelli_race_page(race_url: str):\n",
    "    \"\"\"\n",
    "    Enhanced debugging specifically for Pirelli race pages.\n",
    "    \"\"\"\n",
    "    print(f\"ğŸ” Deep analysis of: {race_url}\")\n",
    "    \n",
    "    soup = get_page_content(race_url)\n",
    "    if not soup:\n",
    "        return None\n",
    "    \n",
    "    print(\"\\nğŸ“„ Page title:\")\n",
    "    title = soup.find('title')\n",
    "    print(title.get_text() if title else \"No title found\")\n",
    "    \n",
    "    # Look for the main content area\n",
    "    print(\"\\nğŸ¯ Main content structure:\")\n",
    "    main_content = soup.find('main') or soup.find('div', class_=re.compile(r'content|main'))\n",
    "    if main_content:\n",
    "        print(\"âœ… Found main content area\")\n",
    "    \n",
    "    # Look for infographic containers\n",
    "    print(\"\\nğŸ–¼ï¸ Infographic analysis:\")\n",
    "    # Common patterns for infographic containers\n",
    "    infographic_selectors = [\n",
    "        {'class': re.compile(r'infographic', re.I)},\n",
    "        {'class': re.compile(r'chart', re.I)},\n",
    "        {'class': re.compile(r'data', re.I)},\n",
    "        {'id': re.compile(r'infographic', re.I)}\n",
    "    ]\n",
    "    \n",
    "    infographic_containers = []\n",
    "    for selector in infographic_selectors:\n",
    "        containers = soup.find_all('div', selector)\n",
    "        infographic_containers.extend(containers)\n",
    "    \n",
    "    print(f\"Found {len(infographic_containers)} potential infographic containers\")\n",
    "    \n",
    "    # Analyze images more thoroughly\n",
    "    images = soup.find_all('img')\n",
    "    tire_related_images = []\n",
    "    for img in images:\n",
    "        src = img.get('src', '').lower()\n",
    "        alt = img.get('alt', '').lower()\n",
    "        \n",
    "        if any(keyword in src + alt for keyword in ['tire', 'tyre', 'compound', 'circuit', 'track', 'infographic']):\n",
    "            tire_related_images.append(img)\n",
    "            print(f\"  ğŸ¯ Relevant image: {alt[:50]} | {src}\")\n",
    "    \n",
    "    # Look for tire compound data in various formats\n",
    "    print(f\"\\nğŸ› Tire compound extraction:\")\n",
    "    page_text = soup.get_text()\n",
    "    \n",
    "    # Enhanced compound detection\n",
    "    compound_patterns = [\n",
    "        r'soft[:\\s]*C([1-5])',\n",
    "        r'medium[:\\s]*C([1-5])',\n",
    "        r'hard[:\\s]*C([1-5])',\n",
    "        r'C([1-5])[:\\s]*soft',\n",
    "        r'C([1-5])[:\\s]*medium',\n",
    "        r'C([1-5])[:\\s]*hard'\n",
    "    ]\n",
    "    \n",
    "    compounds_found = {}\n",
    "    for pattern in compound_patterns:\n",
    "        matches = re.findall(pattern, page_text, re.IGNORECASE)\n",
    "        if matches:\n",
    "            compound_type = pattern.split('[')[0].replace('C([1-5])[:\\\\s]*', '').replace('[:\\\\s]*C([1-5])', '')\n",
    "            compounds_found[compound_type] = matches\n",
    "    \n",
    "    print(f\"Compound patterns found: {compounds_found}\")\n",
    "    \n",
    "    # Look for circuit characteristics in structured format\n",
    "    print(f\"\\nğŸ“Š Track characteristics analysis:\")\n",
    "    \n",
    "    # Try to find characteristics in tables or structured lists\n",
    "    tables = soup.find_all('table')\n",
    "    for i, table in enumerate(tables):\n",
    "        table_text = table.get_text().lower()\n",
    "        if any(keyword in table_text for keyword in ['traction', 'grip', 'braking', 'stress']):\n",
    "            print(f\"  ğŸ“‹ Relevant table {i+1} found\")\n",
    "            rows = table.find_all('tr')\n",
    "            for row in rows[:5]:  # Show first 5 rows\n",
    "                print(f\"    {row.get_text().strip()}\")\n",
    "    \n",
    "    # Look for definition lists or structured data\n",
    "    dl_elements = soup.find_all('dl')  # Definition lists\n",
    "    for dl in dl_elements:\n",
    "        dl_text = dl.get_text().lower()\n",
    "        if any(keyword in dl_text for keyword in ['traction', 'grip', 'braking']):\n",
    "            print(f\"  ğŸ“ Definition list with characteristics found\")\n",
    "            break\n",
    "    \n",
    "    # Look for circuit length in multiple formats\n",
    "    print(f\"\\nğŸ“ Circuit length detection:\")\n",
    "    length_patterns = [\n",
    "        r'(\\d+\\.?\\d*)\\s*km',\n",
    "        r'(\\d+,\\d+)\\s*km',\n",
    "        r'length[:\\s]*(\\d+\\.?\\d*)',\n",
    "        r'distance[:\\s]*(\\d+\\.?\\d*)'\n",
    "    ]\n",
    "    \n",
    "    for pattern in length_patterns:\n",
    "        matches = re.findall(pattern, page_text, re.IGNORECASE)\n",
    "        if matches:\n",
    "            print(f\"  Pattern '{pattern}': {matches}\")\n",
    "    \n",
    "    # Return the soup for further analysis\n",
    "    return soup\n",
    "\n",
    "# Test the enhanced debug function\n",
    "print(\"ğŸ”§ Enhanced debug function ready!\")\n",
    "print(\"ğŸ“ Run: debug_pirelli_race_page('URL') to analyze a specific page\")\n",
    "\n",
    "# Automatically run on Hungarian GP\n",
    "hungarian_soup = debug_pirelli_race_page(\"https://www.pirelli.com/global/en-ww/emotions-and-numbers/formula-1-hungarian-grand-prix-2024-136985/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a8f67eba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ§ª Testing race link extraction for 2024...\n",
      "ğŸ“¡ Fetching: https://www.pirelli.com/global/en-ww/emotions-and-numbers/infographics-2024/\n",
      "ğŸ” Extracting F1 race links for 2024...\n",
      "  ğŸ  1. Formula 1 Gulf Air Bahrain Grand Prix 2024 120834\n",
      "  ğŸ  2. Formula 1 Rolex Australian Grand Prix 2024 123044\n",
      "  ğŸ  3. Gp Japan2024 124711\n",
      "  ğŸ  4. Gp China2024 127209\n",
      "  ğŸ  5. Formula 1 Crypto Com Miami Grand Prix 2024 128694\n",
      "  ğŸ  6. Formula 1 Msc Cruises Gran Premio Del Made In Italy E Dell Emilia Romagna 2024 129842\n",
      "  ğŸ  7. Formula 1 Grand Prix De Monaco 2024 130812\n",
      "  ğŸ  8. Formula 1 Pirelli Grand Prix Du Canada 2024 131658\n",
      "  ğŸ  9. Formula 1 Aramco Gran Premio De Espana 2024 133752\n",
      "  ğŸ 10. Formula 1 Qatar Airways Austrian Grand Prix 2024 134873\n",
      "  ğŸ 11. Formula 1 Qatar Airways British Grand Prix 2024 135487\n",
      "  ğŸ 12. Formula 1 Hungarian Grand Prix 2024 136985\n",
      "  ğŸ 13. Formula 1 Rolex Belgian Grand Prix 2024 137042\n",
      "  ğŸ 14. Formula 1 Heineken Dutch Grand Prix 2024 139980\n",
      "  ğŸ 15. Formula 1 Pirelli Gran Premio D Italia 2024 140854\n",
      "  ğŸ 16. Formula 1 Qatar Airways Azerbaijan Grand Prix 2024 141517\n",
      "  ğŸ 17. Formula 1 Singapore Airlines Singapore Grand Prix 2024 142696\n",
      "  ğŸ 18. Formula 1 Pirelli United States Grand Prix 2024 144632\n",
      "  ğŸ 19. Formula 1 Gran Premio De La Ciudad De Mexico 2024 146014\n",
      "  ğŸ 20. Formula 1 Lenovo Grande Premio De Sao Paulo 2024 146847\n",
      "  ğŸ 21. Formula 1 Heineken Silver Las Vegas Grand Prix 2024 148505\n",
      "  ğŸ 22. Formula 1 Qatar Airways Qatar Grand Prix 2024 149275\n",
      "  ğŸ 23. Formula 1 Etihad Airways Abu Dhabi Grand Prix 2024 149872\n",
      "\n",
      "âœ… Successfully extracted 23 race links for 2024\n",
      "âœ… Race count looks good for F1 season!\n",
      "\n",
      "ğŸ“Š Summary:\n",
      "Total 2024 race links found: 23\n",
      "\n",
      "First 5 links:\n",
      "  1. https://www.pirelli.com/global/en-ww/emotions-and-numbers/formula-1-gulf-air-bahrain-grand-prix-2024-120834/\n",
      "  2. https://www.pirelli.com/global/en-ww/emotions-and-numbers/formula-1-rolex-australian-grand-prix-2024-123044/\n",
      "  3. https://www.pirelli.com/global/en-ww/emotions-and-numbers/gp-japan2024-124711/\n",
      "  4. https://www.pirelli.com/global/en-ww/emotions-and-numbers/gp-china2024-127209/\n",
      "  5. https://www.pirelli.com/global/en-ww/emotions-and-numbers/formula-1-crypto-com-miami-grand-prix-2024-128694/\n",
      "  ... and 18 more\n",
      "\n",
      "ğŸ§ª Testing first race link accessibility...\n",
      "ğŸ“¡ Fetching: https://www.pirelli.com/global/en-ww/emotions-and-numbers/formula-1-gulf-air-bahrain-grand-prix-2024-120834/\n",
      "âœ… Successfully accessed: FORMULA 1  GULF AIR BAHRAIN  GRAND PRIX 2024 | Pirelli\n"
     ]
    }
   ],
   "source": [
    "# Test the race link extraction\n",
    "print(\"ğŸ§ª Testing race link extraction for 2024...\")\n",
    "test_2024_links = get_race_links_for_year(2024)\n",
    "\n",
    "print(f\"\\nğŸ“Š Summary:\")\n",
    "print(f\"Total 2024 race links found: {len(test_2024_links)}\")\n",
    "\n",
    "if test_2024_links:\n",
    "    print(f\"\\nFirst 5 links:\")\n",
    "    for i, link in enumerate(test_2024_links[:5]):\n",
    "        print(f\"  {i+1}. {link}\")\n",
    "    \n",
    "    if len(test_2024_links) > 5:\n",
    "        print(f\"  ... and {len(test_2024_links) - 5} more\")\n",
    "        \n",
    "    # Test one link accessibility\n",
    "    print(f\"\\nğŸ§ª Testing first race link accessibility...\")\n",
    "    test_soup = get_page_content(test_2024_links[0])\n",
    "    if test_soup:\n",
    "        title = test_soup.find('title')\n",
    "        print(f\"âœ… Successfully accessed: {title.get_text() if title else 'No title found'}\")\n",
    "    else:\n",
    "        print(\"âŒ Could not access the race page\")\n",
    "else:\n",
    "    print(\"âŒ No race links found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93762d94",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This notebook provides a comprehensive web scraper for Pirelli's F1 tire and circuit data.\n",
    "\n",
    "### What it scrapes:\n",
    "1. **Tire Compounds** - Official C1-C5 designations for soft/medium/hard\n",
    "2. **Circuit Length** - Track distance in kilometers\n",
    "3. **Track Characteristics** (1-5 scale):\n",
    "   - Traction\n",
    "   - Asphalt Grip\n",
    "   - Tire Stress\n",
    "   - Braking\n",
    "   - Lateral Forces\n",
    "   - Downforce\n",
    "   - Asphalt Abrasion\n",
    "   - Track Evolution\n",
    "\n",
    "### Next Steps:\n",
    "1. **Test** the scraper on a few pages first\n",
    "2. **Refine** extraction functions based on actual HTML structure\n",
    "3. **Run** full scraper for all years (2022-2024)\n",
    "4. **Integrate** data with your F1 tire degradation analysis\n",
    "\n",
    "### Integration with your analysis:\n",
    "The scraped data perfectly complements your FastF1 analysis by providing:\n",
    "- Official tire compound context\n",
    "- Circuit-specific characteristics for modeling\n",
    "- Track evolution and surface data\n",
    "- Braking and cornering intensity metrics\n",
    "\n",
    "This will make your tire degradation analysis much more comprehensive! ğŸï¸ğŸ“Š"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
